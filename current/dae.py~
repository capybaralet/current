import numpy as np
import numpy.random
import pylab
import theano 
import pylearn2
import pylearn2.models.autoencoder as autoencoder

from pylearn2.config import yaml_parse
from pylearn2.utils import serial

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.cm as cm




#Step 0: Set Parameters

# Default to 3 for RGB
numchannels = 3
# We assume a square input of inputdim x inputdim x numchannels
inputdim = 28

nclasses = 10
irange = .5

nhid = [100, 200, 300]
patchsize = [4, 6, 9]
#pooling = [1, 2, 4]
pooling = 1
stdev  = [.3, 1, 3]
#dweight = [30, 90]
dweight = 50
learningrate = .1




dataset = """!obj:pylearn2.datasets.mnist.MNIST {
        which_set: 'train',
        one_hot: 1,
        start: 0,
        stop: 1000
    }"""

model = """!obj:pylearn2.models.autoencoder.DenoisingAutoencoder {
    nhid: 50,
    irange: 0.1,
    act_enc: 'sigmoid',
    act_dec: 'sigmoid',
    nvis: 784,
    corruptor: !obj:pylearn2.corruption.GaussianCorruptor {
            stdev: 0.3,
        },
}"""

algorithm = """!obj:pylearn2.training_algorithms.bgd.BGD {
        cost: !obj:pylearn2.costs.autoencoder.MeanSquaredReconstructionError {
        },
        batch_size: 100,
        line_search_mode: 'exhaustive',
        conjugate: 1,
        monitoring_dataset:
            {
                'train' : *train,
                'valid' : !obj:pylearn2.datasets.mnist.MNIST {
                              which_set: 'train',
                              one_hot: 1,
                              start: 1000,
                              stop:  1200
                          },
                'test'  : !obj:pylearn2.datasets.mnist.MNIST {
                              which_set: 'test',
                              one_hot: 1,
                              start: 0,
                              stop: 200
                          }
            },      
        termination_criterion : !obj:pylearn2.training_algorithms.sgd.EpochCounter {
        "max_epochs": 70,
        }
    }"""
    
    
train = """!obj:pylearn2.train.Train {
    dataset: &train %(dataset)s,
    model: %(model)s,
    algorithm: %(algorithm)s,
    extensions: [
        !obj:pylearn2.train_extensions.best_params.MonitorBasedSaveBest {
             channel_name: 'valid_objective',
             save_path: "dae_best.pkl"
        },
    ],
    save_path: "dae.pkl",
    save_freq: 1
}""" % locals()


train = yaml_parse.load(train)
train.main_loop()


def s(x):
    return 1. / (1. + np.exp(-x)) 


model = serial.load('dae.pkl')
dataset_yaml_src = model.dataset_yaml_src
dataset = yaml_parse.load(dataset_yaml_src)

w1 = model.weights
w2 = model.w_prime
b1 = model.hidbias
b2 = model.visbias
w1 = w1.get_value()
w2 = w2.get_value()
b1 = b1.get_value()
b2 = b2.get_value()

# Plotting this many example input/output pairs
num2plot = 8

inputs = dataset.get_batch_topo(num2plot).reshape(num2plot, inputdim, inputdim)
flat_inputs = inputs.reshape(num2plot, inputdim**2)
h = s(np.dot(flat_inputs,w1)+b1)
flat_outputs = s(np.dot(h,w2)+b2)
outputs = flat_outputs.reshape(num2plot, inputdim, inputdim)

for i in range(num2plot):
    plt.subplot(num2plot,2,2*i+1)
    plt.imshow(inputs[i], cmap = cm.Greys_r)
    plt.subplot(num2plot,2,2*i+2)
    plt.imshow(outputs[i], cmap = cm.Greys_r)

savestr = 'mnist.png'
plt.savefig(savestr)
