"""
Script to train denoising autoencoder on patch-pair, displacement vector data from
CIFAR10.  Uses SGD.

currently, going with one-hot encoding on signed pixel distances for displacement vectors
"""

from pylearn2.corruption import BinomialCorruptor
from pylearn2.corruption import GaussianCorruptor
from pylearn2.costs.mlp import Default
from pylearn2.models.autoencoder import Autoencoder, DenoisingAutoencoder
from pylearn2.training_algorithms.sgd import SGD
from pylearn2.costs.autoencoder import MeanSquaredReconstructionError
from pylearn2.termination_criteria import EpochCounter
from pylearn2.datasets import cifar10
from pylearn2.datasets.dense_design_matrix import DenseDesignMatrix
from pylearn2.datasets.transformer_dataset import TransformerDataset
from pylearn2.training_algorithms.sgd import MonitorBasedLRAdjuster
from pylearn2.train import Train
from pylearn2.datasets import cifar10
from optparse import OptionParser
from pylearn2.datasets import preprocessing

import pylearn2.utils.serial as serial
import os
import numpy as np



MAX_EPOCHS_UNSUPERVISED = 3



num_channels = 3
input_width = 32
# 2D inputs only, code may break in spots for other input_dim values
input_dim = 2

patch_width = 4
# assume 2D for next line
patch_shape = (patch_width, patch_width)
patches_per_image = 2

num_components = num_channels * input_width**input_dim
#num_components = 20
keep_var_fraction = .9

# This is easy enough to change if we look at cifar10.CIFAR10
train_size = 50000

nhid = 40




# Loads the preprocessed dataset, or does the preprocessing and saves the dataset.
# Only the trainset is processed by this function.
# Currently using CIFAR10.

def get_processed_dataset():

    train_path = 'pp_cifar10_train.pkl'
    test_path = 'pp_cifar10_test.pkl'

    if os.path.exists(train_path) and os.path.exists(test_path):
        print 'loading preprocessed data'
        trainset = serial.load(train_path)
        testset = serial.load(test_path)

    else:
        print 'loading raw data...'
        trainset = cifar10.CIFAR10(which_set="train")
        testset =  cifar10.CIFAR10(which_set="test")
	
        pipeline = preprocessing.Pipeline()
        pipeline.items.append(preprocessing.ExtractPatchesWithPosition(patch_shape=patch_shape, patches_per_image=patches_per_image))
        pipeline.items.append(preprocessing.GlobalContrastNormalization(sqrt_bias=10., use_std=True))
        pipeline.items.append(preprocessing.PCA(num_components = num_components, keep_var_fraction = keep_var_fraction))
        pipeline.items.append(preprocessing.ExtractPatchPairs(patches_per_image = patches_per_image, num_images = train_size, input_width = input_width))

        trainset.apply_preprocessor(preprocessor=pipeline, can_fit=True)

        # the pkl-ing is having issues, the dataset is maybe too big.
        serial.save('pp_cifar10_train.pkl', trainset)
        serial.save('pp_cifar10_test.pkl', testset)

        # this path will be used for visualizing weights after training is done
        trainset.yaml_src = '!pkl: "%s"' % train_path
        testset.yaml_src = '!pkl: "%s"' % test_path

    return trainset, testset




def main():

    # Only the trainset is processed by this function.
    trainset, testset = get_processed_dataset()
    
    dmat = trainset.get_design_matrix()
    nvis = dmat.shape[1]

    model = DenoisingAutoencoder(
                                 corruptor = BinomialCorruptor(corruption_level=0.5),
                                 nhid = nhid,
                                 nvis = nvis,
                                 act_enc = 'sigmoid',
                                 act_dec = 'sigmoid',
                                 irange = .01
                                 )

    algorithm = SGD(
                    learning_rate = 0.1,
                    cost =  MeanSquaredReconstructionError(),
                    batch_size =  100,
                    monitoring_batches = 10,
                    monitoring_dataset =  trainset,
                    termination_criterion = EpochCounter(max_epochs=MAX_EPOCHS_UNSUPERVISED),
                    update_callbacks =  None
                    )

    extensions = None

    trainer = Train(model = model,
                algorithm = algorithm,
                save_path='run.pkl',
                save_freq=1,
                extensions = extensions,
                dataset = trainset)

    trainer.main_loop()


if __name__ == '__main__':
    main()
